\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc,url}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{amsmath, amssymb}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{parskip}
\usepackage{lmodern}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{epigraph}
\usepackage{listings}


\begin{document}
\title{FYS3150 -- Project 2}
\author{
    \begin{tabular}{r l}
        Kristian Gregorius Hustad & (\texttt{krihus})\\
        Jonas Gahr Sturtzel Lunde & (\texttt{jonassl})
    \end{tabular}}
%\date{}    % if commented out, the date is set to the current date

\maketitle



% quote
\setlength{\epigraphwidth}{0.75\textwidth}
\renewcommand{\epigraphflush}{center}
\renewcommand{\beforeepigraphskip}{50pt}
\renewcommand{\afterepigraphskip}{100pt}
\renewcommand{\epigraphsize}{\normalsize}

\epigraph{Should array indices start at 0 or 1?  My compromise of 0.5 was rejected without, I thought, proper consideration.}
{\textit{Stan Kelly-Bootle}}

% alternative quote
%\epigraph{The first principle is that you must not fool yourself -- and you are the easiest person to fool.}{\textit{Richard Feynman}}

\begin{abstract}
\noindent
In this report, we show how the probability-distribution of two electrons in an harmonic oscillator well can be solved as an eigenvalue-problem. We will be looking at the behaviour of the probability, with, and without the implementation of the Coulomb force, and different oscillator potential, solved with Jacobi's method.
\end{abstract}

\vfill


\begin{center}
    GitHub repository at \url{https://github.com/KGHustad/FYS3150}
\end{center}

\newpage

%%% MACROS
\newcommand{\half}{\frac{1}{2}}
\newcommand{\dx}{{\Delta x}}
\newcommand{\bigO}{{\mathcal{O}}}
\newcommand{\rhomax}{{\rho_{\mathrm{max}}}}



\section{Introduction}\label{sec:intro}
%\subsection*{Description of the nature of the problem}
SchrÃ¶dinger's equation for an electron in a three-dimensional harmonic oscillator well in spherical coordinates, ignoring the Coulomb force, is
\begin{equation}
  -\frac{\hbar^2}{2 m} \frac{d^2}{dr^2} u(r)
       + \left ( V(r) + \frac{l (l + 1)}{r^2}\frac{\hbar^2}{2 m}
                                    \right ) u(r)  = E u(r) .
\end{equation}
If we discretize this equation at the ground state of the orbital momentum of the electrons, it can be rewritten (as shown in \cite{fys3150_project2}) as an eigenvalue-problem with a tridiagonal matrix:
\begin{equation*}
A\textbf{x} = \lambda \textbf{x}
\end{equation*}
where
\begin{equation}
A = \begin{bmatrix} \frac{2}{h^2}+V_1 & -\frac{1}{h^2} & 0   & 0    & \dots  &0     & 0 \\
                                -\frac{1}{h^2} & \frac{2}{h^2}+V_2 & -\frac{1}{h^2} & 0    & \dots  &0     &0 \\
                                0   & -\frac{1}{h^2} & \frac{2}{h^2}+V_3 & -\frac{1}{h^2}  &0       &\dots & 0\\
                                \dots  & \dots & \dots & \dots  &\dots      &\dots & \dots\\
                                0   & \dots & \dots & \dots  &-\frac{1}{h^2}  &\frac{2}{h^2}+V_{N-2} & -\frac{1}{h^2}\\
                                0   & \dots & \dots & \dots  &\dots       &-\frac{1}{h^2} & \frac{2}{h^2}+V_{N-1}
             \end{bmatrix}
\label{eq:A_matrix}
\end{equation}
It has been shown in \cite{mhj_lecture_notes} that \eqref{eq:A_matrix} can be solved can be solved by Jacobi's method with the following algorithm.




\section{Discussion of methods}\label{sec:methods}
We can solve this eigenvalue-problem by a series of rotations that preserve the orthogonality of the matrix, through Jacobi's rotational method, described in \cite{mhj_lecture_notes}.
\subsection{Preservation of orthogonality}

The transformation $\textbf{w}_i = \textbf{U}\textbf{v}_i$, where U is an orthogonal matrix, is defined as a unitary transformation.
\\
We will show that the unitary transformation $\textbf{w}_i = \textbf{U}\textbf{v}_i$ preserves the the orthogonality of the vector, which can be tested with the dot product $\textbf{v}_j^T\textbf{v}_i = \delta_{ij}$. The dot product of the vectors after the unitary transformation, $\textbf{w}_j^T\textbf{w}_i$, should stay the same.\\
\\
\begin{equation}
\textbf{w}_j^T\textbf{w}_i = (\textbf{U}\textbf{v}_i)^T(\textbf{U}\textbf{v}_j) = (\textbf{v}_i^T\textbf{U}^T)(\textbf{U}\textbf{v}_j) = \textbf{v}_i^T\textbf{I}\textbf{v}_j = \textbf{v}_i^T\textbf{v}_j = \delta_{ij}
\end{equation}
\\
Notes;\\
$(\textbf{U}\textbf{v}_i)^T = \textbf{v}_i^T\textbf{U}^T$,\\
$\textbf{U}^T\textbf{U} = \textbf{I}$ if $\textbf{U}$ is orthogonal.

\subsection{Complexity analysis}

\begin{algorithm}
\caption{Jacobi's method} \label{alg:jacobi}
\begin{algorithmic}[1]
  \Procedure{Jacobi}{$A, R, n, tol$}
  \Statex \Comment{Find $|A_{kl}| = \max\limits_{i,j}(|A_{ij}|) \mid i \neq j$}
  \State $maximum, k, l \gets$ \textsc{Find max non-diagonal symmetrical}$(A,n)$
  \While {$maximum > tol$}
    \State \textsc{Rotate}$(A, R, n, k, l)$
    \State $maximum, k, l \gets$ \textsc{Find max non-diagonal symmetrical}$(A,n)$
  \EndWhile
  \EndProcedure

  \Statex % empty line between procedures

  \Procedure{Rotate}{$A, R, n, k, l$}


  \State $\tau \gets \frac{A_{ll} - A_{kk}}{2A_{kl}}$
  \If {$\tau > 0$}
      \State $t \gets \frac{1}{\tau + \sqrt{1 + \tau^{2}}}$
  \Else
      \State $t \gets \frac{1}{\tau - \sqrt{1 + \tau^{2}}}$
  \EndIf
  \State $c \gets 1 / \sqrt{1+t^{2}}$
  \State $s \gets c \cdot t$

  %# we need to store some values for later use
  \State $a_{kk} \gets A_{kk}$
  \State $a_{ll} \gets A_{ll}$

  \State $A_{kk} \gets c^{2} \cdot a_{kk} - 2 \cdot c \cdot s \cdot A_{kl} + s^{2} \cdot a_{ll}$
  \State $A_{ll} \gets s^{2} \cdot a_{kk} + 2 \cdot c \cdot s \cdot A_{kl} + c^{2} \cdot a_{ll}$
  \State $A_{kl} \gets 0$
  \State $A_{lk} \gets 0$

    \For {$i \gets 0, \dots, n-1$}
        \If {$i \neq k$ and $i \neq l$}
          \State $a_{ik} \gets A_{ik}$
          \State $a_{il} \gets A_{il}$
          \State $A_{ik} \gets c \cdot a_{ik} - s \cdot a_{il}$
          \State $A_{ki} \gets A_{ik}$
          \State $A_{il} \gets c \cdot a_{il} + s \cdot a_{ik}$
          \State $A_{li} \gets A_{il}$
      \EndIf

        \State $r_{ik} \gets R_{ik}$
        \State $r_{il} \gets R_{il}$
        \State $R_{ik} \gets c \cdot r_{ik} - s \cdot r_{il}$
        \State $R_{il} \gets c \cdot r_{il} + s \cdot r_{ik}$
    \EndFor


  \EndProcedure
\end{algorithmic}
\end{algorithm}

Analysing algorithm \ref{alg:jacobi}, we see that the loop in \textsc{Jacobi} runs until a tolerance is reached. For each round in the loop, \textsc{Rotate} and \textsc{Find max non-diagonal symmetrical} are called once each. We see that \textsc{Rotate} runs in $\Theta(n)$ time, albeit with some constant terms which require a substantial number of FLOPs. The algorithm for \textsc{Find max non-diagonal symmetrical} is not listed, but it is trivial to see that finding the maximum non-diagonal element in a symmetrical $n \times n$ matrix takes $\Theta(n^2)$ time.

We shall not attempt to determine how many rotations are required to reach the tolerance analytically, but rather revisit this topic in subsection \ref{subsec:studying_the_results}, armed with experimental data.

\section{Implementation and results}\label{sec:implementation_and_results}

We first implemented the algorithm straightforward in Python, then we rewrote \textsc{Find max non-diagonal symmetrical} in C and called the C function from Python via \href{http://docs.scipy.org/doc/scipy/reference/generated/scipy.weave.inline.html}{\texttt{scipy.weave.inline}}, reducing the runtime by a factor of 10. We did not settle there, but rewrote the entire solver in C, so that the matrices were initialized in Python, and then they were passed into a C function which interfaced with Python via \href{https://docs.python.org/2/library/ctypes.html}{\texttt{ctypes}}. This led to another speedup by a factor of 10.

Going with a hybrid Python/C solution allowed us to combine the speed of C with the many powerful Python libraries we are fond of. All the data are directly available in Python, so we don't have to deal with writing results to a file and all the hassle related to that.

\subsection{Implementing unit tests}
There are several ways of implementing unit tests in Python. For most of the functions, we made a simple doctest which has the strength of being both easy to read and easy to write. In addition, we made a more extensive test which compares the eigenvalues and eigenvectors returned by our algorithm with those returned by \href{http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eigh.html}{\texttt{numpy.linalg.eigh}}.

\subsection{Studying the results}\label{subsec:studying_the_results}
\begin{figure}[ht]
\begin{subfigure}[t]{0.5\textwidth}
\includegraphics[width=\textwidth]{fig/plot_3-lowest_non-interacting_omega=1_rho-max=5_n=200.pdf}
\caption{Choosing $\rhomax = 5$ seems optimal}
\end{subfigure}
\begin{subfigure}[t]{0.5\textwidth}
\includegraphics[width=\textwidth]{fig/plot_3-lowest_non-interacting_omega=1_rho-max=10_n=200.pdf}
\caption{With $\rhomax = 10$, over half the plot is just zero.}
\end{subfigure}
\caption{The 3 lowest energy levels for the non-interacting case}
\label{fig:non-interacting_compare_rho_max}
\end{figure}

From figure \ref{fig:non-interacting_compare_rho_max}, we observe that $N=200$ seems to yield sufficiently accurate values for $\lambda$, with the error being in the fifth significant digit. We also note that doubling $\rhomax$ (while keeping all other parameters constant) causes the error to grow by a factor of 4. This is in agreement with the scheme having an error of the order of $\Theta(h^2)$.

\begin{table}[htbp]
\begin{center}
    \input{table_non_interacting_rho-max=5.dat}
\caption{Results for the non-interacting case with $\rhomax=5$, $\omega=1$ and a tolerance of $10^{-8}$ for selected values of $N$}
\label{table:non-interacting}
\end{center}
\end{table}

In table \ref{table:non-interacting}, we increase $N$ by $\sqrt[4]{2}$. We notice that the number of iterations, i.e. rounds in \textsc{Jacobi}, increases by more than a ratio of 4 by each doubling of N. It seems that the number of iterations is lower bounded by $n^2$ ($\Omega(n^2)$). This means that our algorithm should run in $\Omega(n^4)$ time. We see that the time used roughly doubles for each increase of $N$ by $\sqrt[4]{2}$, so our algorithm runs in $n^4$ time for these $N$ values. If we were to test with even larger $N$, we might see that this is a lower bound, but since the runtime increases so quickly, such an empirical approach may become unfeasible.


\subsubsection{Effect of Coulomb interaction}

\begin{figure}[ht]
    \begin{subfigure}[t]{\textwidth}
        \includegraphics[width=\textwidth]{{fig/plot_varying-omega_non-interacting_omega=0.5,1,5_rho-max=5_n=100}.pdf}
        \caption{Non-interacting case}
    \end{subfigure}

    \begin{subfigure}[t]{\textwidth}
        \includegraphics[width=\textwidth]{{fig/plot_varying-omega_interacting_omega=0.5,1,5_rho-max=5_n=100}.pdf}
        \caption{Interacting case}
    \end{subfigure}

\caption{The lowest energy level for selected $\omega$}
\label{fig:compare_interaction_various_omega}
\end{figure}

From figure \ref{fig:compare_interaction_various_omega} we observe that the interacting case is slightly shifted to the right compared to the non-interacting case. This is due to the repulsive interaction between electrons.


\section{Conclusion}\label{sec:conclusion}
We see that decreasing the strength of the oscillator potential $\omega$ pushes the probability distribution further away from 0, making it shallower. The same goes for the introduction of the Coulomb force.


%\bibliographystyle{plain}
%\bibliographystyle{siam}
\bibliographystyle{IEEEtran}
\bibliography{../papers}{}

\end{document}
